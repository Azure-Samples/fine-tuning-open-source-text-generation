{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3fa6e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Import models from Hugging Face and MMDetection hub\n",
    "This sample shows how to import and register models from [HuggingFace hub](https://huggingface.co/models).\n",
    "\n",
    "For `image-object-detection` and `image-instance-segmentation`, models from MMDetection are supported. Please refer to [import_mmdetection_model_into_registry.ipynb](./import_mmdetection_model_into_registry.ipynb) to import these.\n",
    "\n",
    "### How does import work?\n",
    "The import process runs as a job in your AzureML workspace using components from the `azureml` system registry. The models are downloaded and converted to MLflow packaged format. You can then register the models to your AzureML Workspace or Registry that makes them available for inference or fine tuning. \n",
    "\n",
    "### What models are supported for import?\n",
    "Any model from Hugging Face hub can be downloaded using the `download_model` component. Only the following set of tasks are supported for MLflow conversion:\n",
    "* fill-mask\n",
    "* token-classification\n",
    "* question-answering\n",
    "* summarization\n",
    "* text-generation\n",
    "* text-classification\n",
    "* translation\n",
    "* image-classification\n",
    "\n",
    "Please note that, we also support `image-object-detection` and `image-instance-segmentation` models from MMDetection. To import these, refer to [import_mmdetection_model_into_registry.ipynb](./import_mmdetection_model_into_registry.ipynb).\n",
    "\n",
    "### Limitations of Model Import component where MLFlow conversion of model(s) would fail: \n",
    "1. If you attempt to download a model that has a task type other than the above with error - `Exception: Unsupported task {task name}`. \n",
    "2. If Hugging Face model is on transformers version > 4.28.1. \n",
    "3. If Hugging Face model requires additional dependencies not covered in [requirements.txt](./requirements.txt)\n",
    "4. If Hugging Face model requires custom tokenizer or custom Model architecture which can't be sufficied with transformers AutoTokenizer or AutoModel class.\n",
    "\n",
    "\n",
    "### Why convert to MLflow?\n",
    "MLflow is AzureML's recommended model packaging format. \n",
    "* **Evaluation benefits**: Foundation models imported and converted to MLflow format can be Evaluated using AzureML's Evaluation pipelines. You can use the no-code UI wizards, or the code-based job submission with the SDK or CLI/YAML. AzureML's Evaluation pipelines are built using components. This gives you the flexibility to compose your own Evaluation pipelines using AzureML Evaluation Components and evaluate your Model's performance on standard or custom dataset(s) to take informed decision on whether to deploy the base model directly or further fine-tune it before deployment. Learn more about AzureML Evaluation pipelines using [SDK](https://github.com/Azure/azureml-examples/tree/mabables/foundation-models/sdk/python/foundation-models/system/evaluation) or [CLI](https://github.com/Azure/azureml-examples/tree/mabables/foundation-models/cli/foundation-models/system/evaluation).\n",
    "* **Inference benefits**: AzureML supports no-code-deployment for models packaged as MLflow that enables a seamless inference experience for the models. Learn more about [MLflow model packaging](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow-models) and [no-code-deployment](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-mlflow-models-online-endpoints?tabs=sdk). \n",
    "* **Fine tuning benefits**: Foundation models imported and converted to MLflow format can be fine tuned using AzureML's fine tuning pipelines. You can use the no-code UI wizards, or the code based job submission with the SDK or CLI/YAML. AzureML's fine tuning pipelines are built using components. This gives you the flexibility to compose your own fine tuning pipelines containing your own jobs for data transformation, post processing and the AzureML fine tuning components. Learn more about pipelines using [sdk](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipeline-python) or [CLI](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipelines-cli).\n",
    "\n",
    "### What happens if I just download model and register models without converting to MLflow? That's because the task of the model I'm interested in is not among the supported list of tasks.\n",
    "You can still download and register the model using the outputs of the `download_model` job. You need to [write your own inference code](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-online-endpoints?tabs=python) in this case. It also means that fine tuning is not yet supported if the task type of the model you are interested in is not in the supported list.\n",
    "\n",
    "### Outline\n",
    "1. Connect to Azure Machine Learning Workspace\n",
    "2. Create a pipeline job using the pipeline component for HuggingFace models\n",
    "3. Get the registered model\n",
    "\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription - [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace with computer cluster - [Configure workspace](https://aka.ms/azureml-workspace-configuration)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](https://aka.ms/azureml-sdkv2-install) - check the getting started section\n",
    "\n",
    "\n",
    "**Motivations** - This notebook explains how to create model importing/publishing pipeline job in workspace using pipeline component registered in a registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba6a51",
   "metadata": {},
   "source": [
    "## 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section, we will connect to the workspace in which the job will be run.\n",
    "\n",
    "### 1.1 Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85623da",
   "metadata": {
    "gather": {
     "logged": 1727088112177
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.ai.ml import MLClient, UserIdentityConfiguration\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "from azure.ai.ml.dsl import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911a778",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1.2 Configure credential\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to the workspace. \n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "\n",
    "Reference for more available credentials if it does not work for you: [configure credential example](https://aka.ms/azureml-workspace-configuration), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503c314",
   "metadata": {
    "gather": {
     "logged": 1727088112310
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab6857",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1.3 Get a handle to the workspace and the registry\n",
    "\n",
    "We use the config file to connect to a workspace. The Azure ML workspace should be configured with a computer cluster. [Check this notebook for configure a workspace](https://aka.ms/azureml-workspace-configuration)\n",
    "\n",
    "If config file is not available user can update following parameters in place holders\n",
    "- SUBSCRIPTION_ID\n",
    "- RESOURCE_GROUP\n",
    "- WORKSPACE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7159db",
   "metadata": {
    "gather": {
     "logged": 1727088112590
    }
   },
   "outputs": [],
   "source": [
    "# Get a handle to workspace\n",
    "try:\n",
    "    ml_client_ws = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    ml_client_ws = MLClient(\n",
    "        credential,\n",
    "        subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "        resource_group_name=\"<RESOURCE_GROUP>\",\n",
    "        workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    )\n",
    "\n",
    "ml_client_registry = MLClient(credential, registry_name=\"azureml\")\n",
    "\n",
    "experiment_name = f\"Import-Model-Pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2cede",
   "metadata": {},
   "source": [
    "### 1.4 Compute target setup\n",
    "\n",
    "#### Create or Attach existing AmlCompute\n",
    "A compute target is required to execute the Automated ML run. In this tutorial, you create AmlCompute as your training compute resource.\n",
    "\n",
    "#### Creation of AmlCompute takes approximately 5 minutes. \n",
    "If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002db87",
   "metadata": {
    "gather": {
     "logged": 1727088115022
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "compute_name = \"compute-fine-tuning\"\n",
    "\n",
    "try:\n",
    "    _ = ml_client_ws.compute.get(compute_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "except ResourceNotFoundError:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute(\n",
    "        name=compute_name,\n",
    "        type=\"amlcompute\",\n",
    "        size=\"STANDARD_NC6s_v3\",\n",
    "        idle_time_before_scale_down=120,\n",
    "        min_instances=0,\n",
    "        max_instances=6,\n",
    "    )\n",
    "    ml_client_ws.begin_create_or_update(compute_config).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e53eb8",
   "metadata": {},
   "source": [
    "## 2. Create a pipeline job using the pipeline component for HuggingFace models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f1f1f",
   "metadata": {},
   "source": [
    "### 2.1 Load pipeline component from the registry to create a pipeline\n",
    "\n",
    "- import_model - Pipeline component which downloads the model, converts it into mlflow, validates locally and then register it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04dcbd",
   "metadata": {
    "gather": {
     "logged": 1727042100829
    }
   },
   "outputs": [],
   "source": [
    "import_model = ml_client_registry.components.get(name=\"import_model\", label=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1c389",
   "metadata": {},
   "source": [
    "### 2.2 Create pipeline object using necessary parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8f024",
   "metadata": {},
   "source": [
    "#### Important parameters to pass\n",
    "- model_id                                \n",
    "- compute - Compute cluster on which pipeline job will run\n",
    "- registry_name (optional) - By default, model is imported into your workspace. If registry_name is passed, the pipeline will attempt to register into respective registry\n",
    "\n",
    "#### model_id \n",
    "\n",
    "Browse models on [HuggingFace hub](https://huggingface.co/models) and identify a model to import. Make sure the task type of the model is among the supported tasks as explained in the introduction section. Copy the model id which is available in the URI of the page or can be copied using the copy icon next to the model name and assign it to the variable `MODEL_ID`.\n",
    "\n",
    "\n",
    "![image](image.png)\n",
    "\n",
    "\n",
    "\n",
    "#### token\n",
    "\n",
    "There are a few gated models hosted in HuggingFace, for example the [tiiuae/falcon-180B](https://huggingface.co/tiiuae/falcon-180B) model, which requires the user to accept certain terms and conditions, without which the import component cannot access it directly. To do so, the user would have to create a personal account in HuggingFace and accept terms and conditions. To import such models the user would have to create an Access Token with their HuggingFace account and pass it to the model-import component, after which the model can be downloaded to their workspace or registry. To know the more details , please visit [this link](https://huggingface.co/docs/hub/security-tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb68542",
   "metadata": {},
   "source": [
    "__NOTE: Models from Hugging Face or MMDetection are subject to third party license terms available on the Hugging Face model details page or MMDetection model details page respectively. It is your responsibility to comply with the model's license terms.__\n",
    "#### Set parameter values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c16711",
   "metadata": {
    "gather": {
     "logged": 1727042703721
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "AUTHOR = \"teknium\"\n",
    "MODEL_ID = \"OpenHermes-2.5-Mistral-7B\"\n",
    "TASK_NAME = \"text-generation\"\n",
    "TOKEN = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8598fc-d44b-4069-ad30-0c4bc26b6e77",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "ImportError: cannot import name 'ModelFilter' from 'huggingface_hub'\n",
    "\n",
    "Resolved by not using ModelFilter - depreciated in huggingface > 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208871d",
   "metadata": {
    "gather": {
     "logged": 1727042753775
    }
   },
   "outputs": [],
   "source": [
    "# Check if the MODEL_ID passed is a valid HuggingFace ID\n",
    "from huggingface_hub import HfApi, ModelFilter\n",
    "\n",
    "hf_api = HfApi()  # by default endpoint points to https://huggingface.co\n",
    "model_infos = [\n",
    "    info\n",
    "    for info in hf_api.list_models(search=MODEL_ID, author=AUTHOR)\n",
    "]\n",
    "\n",
    "valid_hf_id = False\n",
    "if model_infos and model_infos[0].modelId == AUTHOR + \"/\" + MODEL_ID:\n",
    "    valid_hf_id = True\n",
    "\n",
    "if not valid_hf_id:\n",
    "    raise ValueError(\n",
    "        \"Found invalid HF ID. Please select the correct HF ID and try again.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df6db4",
   "metadata": {
    "gather": {
     "logged": 1727042843442
    }
   },
   "outputs": [],
   "source": [
    "COMPUTE = compute_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7178a91",
   "metadata": {},
   "source": [
    "#### Check if the model already exists in AzureML registry\n",
    "\n",
    "- it is important to check the correct provider: azureml, meta, ms registry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ea15c",
   "metadata": {
    "gather": {
     "logged": 1727043122313
    }
   },
   "outputs": [],
   "source": [
    "huggingface_model_exists_in_registry = False\n",
    "try:\n",
    "    REG_MODEL_ID = MODEL_ID.replace(\n",
    "        \"/\", \"-\"\n",
    "    )  # model name in registry doesn't contain '/'\n",
    "    models = ml_client_registry.models.list(name=REG_MODEL_ID)\n",
    "    if models:\n",
    "        max_version = (max(models, key=lambda x: int(x.version))).version\n",
    "        model_version = str(int(max_version))\n",
    "        print(\n",
    "            f\"Model already exists in azureml with name {REG_MODEL_ID} and version {model_version}\"\n",
    "        )\n",
    "        huggingface_model_exists_in_registry = True\n",
    "except:\n",
    "    print(\n",
    "        f\"Model {MODEL_ID} has not been imported into the registry. Please continue importing the model.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd925e0",
   "metadata": {},
   "source": [
    "### 2.3 Create pipeline using pipeline component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869b9c2",
   "metadata": {
    "gather": {
     "logged": 1727043452562
    }
   },
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def model_import_pipeline(model_id, compute, task_name, token=None):\n",
    "    \"\"\"\n",
    "    Create model import pipeline using pipeline component.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_id : str\n",
    "    compute : str\n",
    "    task_name : str\n",
    "    token : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_registration_details : dict\n",
    "    \"\"\"\n",
    "    import_model_job = import_model(\n",
    "        model_id=model_id, compute=compute, task_name=task_name, token=token\n",
    "    )\n",
    "\n",
    "    # Set job to not continue on failure\n",
    "    import_model_job.settings.continue_on_step_failure = False\n",
    "\n",
    "    return {\n",
    "        \"model_registration_details\": import_model_job.outputs.model_registration_details\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c3616",
   "metadata": {},
   "source": [
    "### 2.4 Create pipeline object\n",
    "Assign User Identity Configuration to pipeline object, so that individual pipeline components can get identity credentials if required. \n",
    "Click [here](https://learn.microsoft.com/en-us/samples/azure/azureml-examples/azureml---on-behalf-of-feature/) to know more about OBO credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac1908a-5b6e-4736-9602-9ad1213fc1ff",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "will be registered in azureml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9352fe-3700-4766-9177-230a3e93b3d2",
   "metadata": {
    "gather": {
     "logged": 1727044893432
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ID_ = AUTHOR + \"/\" + MODEL_ID\n",
    "ID_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85dc2b8",
   "metadata": {
    "gather": {
     "logged": 1727044900743
    }
   },
   "outputs": [],
   "source": [
    "pipeline_object = model_import_pipeline(\n",
    "    model_id=ID_, compute=COMPUTE, task_name=TASK_NAME, token=TOKEN\n",
    ")\n",
    "pipeline_object.identity = UserIdentityConfiguration()\n",
    "\n",
    "pipeline_object.settings.force_rerun = True\n",
    "\n",
    "\n",
    "pipeline_object.settings.default_compute = COMPUTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5265f",
   "metadata": {},
   "source": [
    "### 2.5 Submit model importing pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47762852",
   "metadata": {
    "gather": {
     "logged": 1727044905992
    }
   },
   "outputs": [],
   "source": [
    "schedule_huggingface_model_import = (\n",
    "    not huggingface_model_exists_in_registry\n",
    "    and MODEL_ID not in [None, \"None\"]\n",
    "    and len(MODEL_ID) > 1\n",
    ")\n",
    "print(\n",
    "    f\"Need to schedule run for importing {MODEL_ID}: {schedule_huggingface_model_import}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1732c9",
   "metadata": {
    "gather": {
     "logged": 1727048567026
    }
   },
   "outputs": [],
   "source": [
    "huggingface_pipeline_job = None\n",
    "if schedule_huggingface_model_import:\n",
    "    # submit the pipeline job\n",
    "    huggingface_pipeline_job = ml_client_ws.jobs.create_or_update(\n",
    "        pipeline_object, experiment_name=experiment_name\n",
    "    )\n",
    "    # wait for the pipeline job to complete\n",
    "    ml_client_ws.jobs.stream(huggingface_pipeline_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d5c80",
   "metadata": {},
   "source": [
    "## 3. Get the registered model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1f809",
   "metadata": {},
   "source": [
    "### 3.1 Download model registration details in local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "download_path = \"./pipeline_outputs/\"\n",
    "\n",
    "# delete the folder if already exists\n",
    "if os.path.exists(download_path):\n",
    "    shutil.rmtree(download_path)\n",
    "\n",
    "# if pipeline job was not scheduled, skip\n",
    "if huggingface_pipeline_job is not None:\n",
    "    print(\"Pipeline job: \" + huggingface_pipeline_job.name)\n",
    "    print(\"Downloading pipeline job output: model_registration_details\")\n",
    "\n",
    "    pipeline_download_path = os.path.join(download_path, huggingface_pipeline_job.name)\n",
    "    os.makedirs(pipeline_download_path, exist_ok=True)\n",
    "\n",
    "    ml_client_ws.jobs.download(\n",
    "        name=huggingface_pipeline_job.name,\n",
    "        download_path=pipeline_download_path,\n",
    "        output_name=\"model_registration_details\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5504e6f",
   "metadata": {},
   "source": [
    "### 3.2 Read registration details and get model from registry/workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9380d0-015a-44e1-9bdf-203980806065",
   "metadata": {
    "gather": {
     "logged": 1727088240744
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import mlflow, json\n",
    "\n",
    "\n",
    "mlflow_tracking_uri = ml_client_ws.workspaces.get(\n",
    "    ml_client_ws.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b079159-891d-46b1-ab1a-e4862b73308b",
   "metadata": {
    "gather": {
     "logged": 1727088245274
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow_tracking_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc61550-5cfd-4a38-a0eb-3b6ff5d75462",
   "metadata": {
    "gather": {
     "logged": 1727088635868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cdfc2d-7816-4ea5-b404-50e9de151eb9",
   "metadata": {
    "gather": {
     "logged": 1727088603975
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# concat 'tags.mlflow.rootRunId=' and pipeline_job.name in single quotes as filter variable\n",
    "filter = \"tags.mlflow.rootRunId='\" + 'affable_hat_9mpkjrvgmq' + \"'\"\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[experiment_name], filter_string=filter, output_format=\"list\"\n",
    ")\n",
    "training_run = None\n",
    "evaluation_run = None\n",
    "# get the training and evaluation runs.\n",
    "# using a hacky way till 'Bug 2320997: not able to show eval metrics in FT notebooks - mlflow client now showing display names' is fixed\n",
    "for run in runs:\n",
    "    # check if run.data.metrics.epoch exists\n",
    "    if \"epoch\" in run.data.metrics:\n",
    "        training_run = run\n",
    "    # else, check if run.data.metrics.accuracy exists\n",
    "    elif \"rouge1\" in run.data.metrics:\n",
    "        evaluation_run = run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f3564-224f-406e-a19c-741398478a20",
   "metadata": {
    "gather": {
     "logged": 1727088387111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load the workspace from the configuration file\n",
    "from azureml.core import Workspace, Model\n",
    "\n",
    "model_name = 'teknium-OpenHermes-2-5-Mistral-7B'\n",
    "version = 1\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "model = Model(ws, name=model_name, version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a596bd-197c-4e34-a2a1-0c78ab06bdc5",
   "metadata": {
    "gather": {
     "logged": 1727088406591
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n{model_name}\")\n",
    "print(model.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e9ac0",
   "metadata": {
    "gather": {
     "logged": 1727049432804
    }
   },
   "outputs": [],
   "source": [
    "'''import json\n",
    "\n",
    "# if pipeline job was not scheduled, skip\n",
    "if huggingface_pipeline_job is not None:\n",
    "    with open(\n",
    "        f\"./pipeline_outputs/{huggingface_pipeline_job.name}/named-outputs/model_registration_details/model_registration_details.json\",\n",
    "        \"r\",\n",
    "    ) as f:\n",
    "        registration_details = json.load(f)\n",
    "\n",
    "    model_name = registration_details[\"name\"]\n",
    "    model_version = registration_details[\"version\"]\n",
    "\n",
    "    # Get the model object from workspace\n",
    "    model = ml_client_ws.models.get(name=model_name, version=model_version)\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(model.__dict__)''"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernel_info": {
   "name": "condav0"
  },
  "kernelspec": {
   "display_name": "condav0",
   "language": "python",
   "name": "condav0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
